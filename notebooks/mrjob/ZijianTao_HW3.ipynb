{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://cse-z2tao/ AKIAIIJOUB4ZRR3CIAAA z2tao\n",
      "total 1039968\n",
      "-rw-r-----@   1 Jacob  staff    5568397 Apr 24 14:53 3.PCA.pdf\n",
      "-rw-r-----@   1 Jacob  staff    3620093 Apr 25 11:57 4.SGD-for-PCA.pdf\n",
      "-rw-r--r--    1 Jacob  staff        537 May 27 19:39 ADC10-1.p\n",
      "-rw-r-----@   1 Jacob  staff    7672937 May 21 07:22 ALL.csv\n",
      "-rw-r--r--    1 Jacob  staff        192 May  5 16:35 Creds.pkl\n",
      "-rw-r--r--@   1 Jacob  staff  355637039 Apr 21 13:20 DailyDiffs.pkl\n",
      "-rw-r-----@   1 Jacob  staff   46545772 Apr 26 15:41 DailyDiffs.pkl.zip\n",
      "-rw-------@   1 Jacob  staff       1696 May 27 13:17 May2015HadoopKeyPair.pem\n",
      "-rw-r--r--    1 Jacob  staff     260650 May 29 00:11 centroids000\n",
      "-rw-r--r--    1 Jacob  staff     501345 May 29 00:21 centroids0001\n",
      "-rw-r--r--    1 Jacob  staff     505939 May 29 00:32 centroids0002\n",
      "-rw-r--r--    1 Jacob  staff     507613 May 29 00:34 centroids0003\n",
      "-rw-r--r--    1 Jacob  staff     153201 May 29 00:31 centroids0004\n",
      "-rw-r--r--    1 Jacob  staff     153179 May 29 00:36 centroids0005\n",
      "-rw-r--r--    1 Jacob  staff     153198 May 29 00:42 centroids0006\n",
      "-rw-r--r--    1 Jacob  staff     149902 May 28 21:16 centroids0007\n",
      "-rw-r--r--    1 Jacob  staff     149692 May 28 21:21 centroids0008\n",
      "-rw-r--r--    1 Jacob  staff     150181 May 28 21:26 centroids0009\n",
      "-rw-r-----@   1 Jacob  staff      18108 Apr 29 23:30 constituents.csv\n",
      "-rw-r--r--    1 Jacob  staff      22213 May 27 09:01 initCentroids.csv\n",
      "-rw-r--r--    1 Jacob  staff      42888 May 26 14:32 initCentroids.json\n",
      "-rw-r--r--    1 Jacob  staff      47010 May 27 10:40 interation1.csv\n",
      "-rw-r--r--    1 Jacob  staff      55019 May 26 11:38 interation1_local.csv\n",
      "drwxr-xr-x    2 Jacob  staff         68 May 27 09:26 \u001b[1m\u001b[36miter\u001b[m\u001b[m\n",
      "drwxr-xr-x    3 Jacob  staff        102 May  5 16:33 \u001b[1m\u001b[36mlogs\u001b[m\u001b[m\n",
      "-rw-r--r--    1 Jacob  staff    1230070 May 27 11:19 processed_ALL.csv\n",
      "drwxr-xr-x@ 489 Jacob  staff      16626 Apr 26 15:46 \u001b[1m\u001b[36mspdata_csv\u001b[m\u001b[m\n",
      "-rw-r-----@   1 Jacob  staff  109259260 Apr 26 15:43 spdata_csv.tgz\n",
      "-rw-r-----@   1 Jacob  staff        111 May  5 15:59 z2tao_aws_credentials.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# Get enviroment variables set from utils/setup.sh\n",
    "os.environ[\"EC2_VAULT\"] = '/Users/Jacob/Desktop/255'\n",
    "os.environ[\"BD_GitRoot\"] = '/Users/Jacob/UCSD_BigData_2015'\n",
    "home_dir = os.environ['HOME']\n",
    "root_dir = os.environ['BD_GitRoot']\n",
    "\n",
    "# Add utils to the python system path\n",
    "sys.path.append(root_dir + '/utils')\n",
    "# Read AWS credentials from 'EC2_VAULT'/Creds.pkl \n",
    "from read_mrjob_creds import *\n",
    "(key_id, secret_key, s3_bucket, username) = read_credentials()\n",
    "print s3_bucket,key_id,username\n",
    "\n",
    "raw_file_dir = '/Users/Jacob/Desktop/255'\n",
    "!ls -l $raw_file_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.protocol import RawValueProtocol\n",
    "from sys import stderr\n",
    "import random\n",
    "\n",
    "#logfile=open('logging','w')\n",
    "logfile=stderr\n",
    "\n",
    "def emptyEntriesMoreThan(arr, num):\n",
    "    return sum([d == '' for d in arr ]) > num\n",
    "\n",
    "class MRPreprocess(MRJob):\n",
    "    OUTPUT_PROTOCOL = RawValueProtocol\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        #logfile.write(\"mapper start\")\n",
    "        if line.startswith(\"station\"):\n",
    "            yield (0, line)\n",
    "        else:\n",
    "            arr = line.split(\",\")\n",
    "            if arr[1] != \"TMAX\":\n",
    "                yield (2, line)\n",
    "            elif emptyEntriesMoreThan(arr, 50):\n",
    "                yield (1, line)\n",
    "            else:\n",
    "                yield (3, line)\n",
    "        \n",
    "    def combiner(self, key, line):\n",
    "        line = [l for l in line]\n",
    "        #logfile.write(\"combiner start\")\n",
    "        if key == 3:\n",
    "            logfile.write(\"======== {} valid lines\\n\".format(len(line)))\n",
    "            for l in line:\n",
    "                yield (random.random(), l)\n",
    "        else:\n",
    "            for l in line:\n",
    "                yield(key, l)\n",
    "\n",
    "    def reducer(self, key, lines):\n",
    "        #logfile.write(\"start reducer\\n\")\n",
    "        #logfile.write(\"val is {}\\n\".format(MRPreprocess.val))\n",
    "        arr = [l for l in lines]\n",
    "        # logfile.write(arr[0])\n",
    "        if key == 0:        \n",
    "            yield ('', arr[0])\n",
    "        elif key == 1:\n",
    "            logfile.write(\"======== {} TMAX entries with more than 50 empty slots\\n\".format(len(arr)))\n",
    "        elif key == 2:\n",
    "            logfile.write(\"======== {} Non-TMAX entries\\n\".format(len(arr)))\n",
    "        else:\n",
    "            yield('', arr[0])\n",
    "        \n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRPreprocess.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess in inline mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/Jacob/.mrjob.conf\n",
      "creating tmp directory /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.014040.663459\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.014040.663459/step-0-mapper_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.014040.663459/step-0-mapper-sorted\n",
      "> sort /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.014040.663459/step-0-mapper_part-00000\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.014040.663459/step-0-reducer_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.014040.663459/step-0-reducer_part-00000 -> /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.014040.663459/output/part-00000\n",
      "Streaming final output from /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.014040.663459/output\n",
      "removing tmp directory /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.014040.663459\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/Users/Jacob/Desktop/255'\n",
    "output_dir = '/Users/Jacob/Desktop/255'\n",
    "!python preprocess1.py --runner=inline $input_dir/ALL.csv > $output_dir/processed_ALL.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting initCentroids.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile initCentroids.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.protocol import RawValueProtocol \n",
    "from sys import stderr\n",
    "import random\n",
    "\n",
    "#logfile=open('log','w')\n",
    "logfile=stderr\n",
    "class MRInitCentroids(MRJob):\n",
    "    OUTPUT_PROTOCOL = RawValueProtocol   \n",
    "    \n",
    "    def configure_options(self):\n",
    "        super(MRInitCentroids, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--k', type='int', help='Number of clusters')\n",
    "        self.add_passthrough_option(\n",
    "            '--l', type='int', help='num of lines to choose from')\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        if random.randint(0, self.options.l) < self.options.k*2:\n",
    "            yield (None, line.split(\",\")[3:])\n",
    "    \n",
    "    def reducer(self, _, line):\n",
    "        # output int array\n",
    "        for l in line:\n",
    "            #for i in range(len(l)):\n",
    "                #l[i] = int(l[i]) if l[i] != \"\" else None\n",
    "            yield (None, \",\".join(l))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRInitCentroids.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/Jacob/.mrjob.conf\n",
      "creating tmp directory /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942\n",
      "writing wrapper script to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/setup-wrapper.sh\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/step-0-mapper_part-00000\n",
      "> sh -ex setup-wrapper.sh /usr/bin/python initCentroids.py --step-num=0 --mapper --k 10 --l 800 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/input_part-00000 > /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/step-0-mapper_part-00000\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/step-0-mapper_part-00001\n",
      "> sh -ex setup-wrapper.sh /usr/bin/python initCentroids.py --step-num=0 --mapper --k 10 --l 800 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/input_part-00001 > /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/step-0-mapper_part-00001\n",
      "STDERR: + __mrjob_PWD=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/mapper/0\n",
      "STDERR: + exec\n",
      "STDERR: + /usr/bin/python -c 'import fcntl; fcntl.flock(9, fcntl.LOCK_EX)'\n",
      "STDERR: + export PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/mapper/0/mrjob.tar.gz:\n",
      "STDERR: + PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/mapper/0/mrjob.tar.gz:\n",
      "STDERR: + exec\n",
      "STDERR: + cd /private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/mapper/0\n",
      "STDERR: + /usr/bin/python initCentroids.py --step-num=0 --mapper --k 10 --l 800 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/input_part-00000\n",
      "STDERR: + __mrjob_PWD=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/mapper/1\n",
      "STDERR: + exec\n",
      "STDERR: + /usr/bin/python -c 'import fcntl; fcntl.flock(9, fcntl.LOCK_EX)'\n",
      "STDERR: + export PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/mapper/1/mrjob.tar.gz:\n",
      "STDERR: + PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/mapper/1/mrjob.tar.gz:\n",
      "STDERR: + exec\n",
      "STDERR: + cd /private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/mapper/1\n",
      "STDERR: + /usr/bin/python initCentroids.py --step-num=0 --mapper --k 10 --l 800 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/input_part-00001\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/step-0-mapper-sorted\n",
      "> sort /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/step-0-mapper_part-00000 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/step-0-mapper_part-00001\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/step-0-reducer_part-00000\n",
      "> sh -ex setup-wrapper.sh /usr/bin/python initCentroids.py --step-num=0 --reducer --k 10 --l 800 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/input_part-00000 > /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/step-0-reducer_part-00000\n",
      "STDERR: + __mrjob_PWD=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/reducer/0\n",
      "STDERR: + exec\n",
      "STDERR: + /usr/bin/python -c 'import fcntl; fcntl.flock(9, fcntl.LOCK_EX)'\n",
      "STDERR: + export PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/reducer/0/mrjob.tar.gz:\n",
      "STDERR: + PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/reducer/0/mrjob.tar.gz:\n",
      "STDERR: + exec\n",
      "STDERR: + cd /private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/job_local_dir/0/reducer/0\n",
      "STDERR: + /usr/bin/python initCentroids.py --step-num=0 --reducer --k 10 --l 800 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/input_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/step-0-reducer_part-00000 -> /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/output/part-00000\n",
      "Streaming final output from /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942/output\n",
      "removing tmp directory /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/initCentroids.Jacob.20150527.153224.839942\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/Users/Jacob/Desktop/255'\n",
    "output_dir = '/Users/Jacob/Desktop/255'\n",
    "!python initCentroids.py --k=10 --l=800 --runner=local $input_dir/processed_ALL.csv > $output_dir/initCentroids.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting updateCentroids.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile updateCentroids.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.protocol import RawValueProtocol \n",
    "from mrjob.protocol import JSONValueProtocol \n",
    "from sys import stderr\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "\n",
    "def dist(arr1, arr2):\n",
    "    dist = 0\n",
    "    for i in range(len(arr1)):\n",
    "        if arr1[i] != None and arr2[i] != None:\n",
    "            dist += (arr1[i] - arr2[i])**2\n",
    "    return dist\n",
    "\n",
    "def strToFltArr(arr):\n",
    "    for i in range(len(arr)):\n",
    "        try:\n",
    "            arr[i] = float(arr[i])\n",
    "        except:\n",
    "            arr[i] = None\n",
    "    return arr\n",
    "\n",
    "logfile=stderr\n",
    "class MRUpdateCentroids(MRJob):\n",
    "    INPUT_PROTOCOL = RawValueProtocol\n",
    "    #OUTPUT_PROTOCOL = RawValueProtocol\n",
    "    \n",
    "    def configure_options(self):\n",
    "        super(MRUpdateCentroids, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--k', type='int', help='Number of clusters')\n",
    "        self.add_file_option('--centroids')\n",
    "        \n",
    "    def mapper_init(self):\n",
    "        #logfile.write(\"mapper init\")\n",
    "        f = open(self.options.centroids)\n",
    "        self.centroids = []\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            if i == self.options.k:\n",
    "                break\n",
    "            self.centroids.append(strToFltArr(line.strip().split(\",\")))\n",
    "            i += 1\n",
    "        #logfile.write(\"----{} centroids received-----\".format(len(self.centroids)))\n",
    "        f.close()\n",
    "        #yield None, self.centroids\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        #logfile.write(\"mapper\")\n",
    "        if not line.startswith(\"station\"):\n",
    "            line = strToFltArr(line.split(\",\")[3:])\n",
    "            minDist = sys.maxint\n",
    "            center = 0\n",
    "            for i in range(len(self.centroids)):\n",
    "                if dist(line, self.centroids[i]) < minDist:\n",
    "                    minDist = dist(line, self.centroids[i])\n",
    "                    center = i\n",
    "            yield (center, line)\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "    def reducer(self, center, lines):\n",
    "        #logfile.write(\"reducer {}\".format(center))\n",
    "        centroid = [0]*365\n",
    "        line = [l for l in lines]\n",
    "        ADC = 0\n",
    "        #logfile.write(\"now center for {}\".format(center))\n",
    "        for l in line:\n",
    "            for i in range(len(l)):\n",
    "                #logfile.write(\"======\")\n",
    "                #logfile.write(str(centroid[i]))\n",
    "                #logfile.write(\"~~\")\n",
    "                #logfile.write(str(l[i]))\n",
    "                centroid[i] += l[i] if l[i] != None else 0\n",
    "        for i in range(len(centroid)):\n",
    "            centroid[i] = centroid[i] * 1.0 / len(line)\n",
    "        # calculate ADC\n",
    "        for l in line:\n",
    "            ADC += math.sqrt(dist(l, centroid))\n",
    "        yield(ADC/len(line), \",\".join([str(d) for d in centroid]))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRUpdateCentroids.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/Jacob/.mrjob.conf\n",
      "creating tmp directory /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072\n",
      "writing wrapper script to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/setup-wrapper.sh\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-mapper_part-00000\n",
      "> sh -ex setup-wrapper.sh /usr/bin/python updateCentroids.py --step-num=0 --mapper --centroids initCentroids.csv --k 10 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/input_part-00000 > /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-mapper_part-00000\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-mapper_part-00001\n",
      "> sh -ex setup-wrapper.sh /usr/bin/python updateCentroids.py --step-num=0 --mapper --centroids initCentroids.csv --k 10 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/input_part-00001 > /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-mapper_part-00001\n",
      "STDERR: + __mrjob_PWD=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/mapper/0\n",
      "STDERR: + exec\n",
      "STDERR: + /usr/bin/python -c 'import fcntl; fcntl.flock(9, fcntl.LOCK_EX)'\n",
      "STDERR: + export PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/mapper/0/mrjob.tar.gz:\n",
      "STDERR: + PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/mapper/0/mrjob.tar.gz:\n",
      "STDERR: + exec\n",
      "STDERR: + cd /private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/mapper/0\n",
      "STDERR: + /usr/bin/python updateCentroids.py --step-num=0 --mapper --centroids initCentroids.csv --k 10 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/input_part-00000\n",
      "STDERR: + __mrjob_PWD=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/mapper/1\n",
      "STDERR: + exec\n",
      "STDERR: + /usr/bin/python -c 'import fcntl; fcntl.flock(9, fcntl.LOCK_EX)'\n",
      "STDERR: + export PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/mapper/1/mrjob.tar.gz:\n",
      "STDERR: + PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/mapper/1/mrjob.tar.gz:\n",
      "STDERR: + exec\n",
      "STDERR: + cd /private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/mapper/1\n",
      "STDERR: + /usr/bin/python updateCentroids.py --step-num=0 --mapper --centroids initCentroids.csv --k 10 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/input_part-00001\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-mapper-sorted\n",
      "> sort /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-mapper_part-00000 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-mapper_part-00001\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-reducer_part-00000\n",
      "> sh -ex setup-wrapper.sh /usr/bin/python updateCentroids.py --step-num=0 --reducer --centroids initCentroids.csv --k 10 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/input_part-00000 > /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-reducer_part-00000\n",
      "writing to /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-reducer_part-00001\n",
      "> sh -ex setup-wrapper.sh /usr/bin/python updateCentroids.py --step-num=0 --reducer --centroids initCentroids.csv --k 10 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/input_part-00001 > /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-reducer_part-00001\n",
      "STDERR: + __mrjob_PWD=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/reducer/0\n",
      "STDERR: + exec\n",
      "STDERR: + /usr/bin/python -c 'import fcntl; fcntl.flock(9, fcntl.LOCK_EX)'\n",
      "STDERR: + export PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/reducer/0/mrjob.tar.gz:\n",
      "STDERR: + PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/reducer/0/mrjob.tar.gz:\n",
      "STDERR: + exec\n",
      "STDERR: + cd /private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/reducer/0\n",
      "STDERR: + /usr/bin/python updateCentroids.py --step-num=0 --reducer --centroids initCentroids.csv --k 10 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/input_part-00000\n",
      "STDERR: + __mrjob_PWD=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/reducer/1\n",
      "STDERR: + exec\n",
      "STDERR: + /usr/bin/python -c 'import fcntl; fcntl.flock(9, fcntl.LOCK_EX)'\n",
      "STDERR: + export PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/reducer/1/mrjob.tar.gz:\n",
      "STDERR: + PYTHONPATH=/private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/reducer/1/mrjob.tar.gz:\n",
      "STDERR: + exec\n",
      "STDERR: + cd /private/var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/job_local_dir/0/reducer/1\n",
      "STDERR: + /usr/bin/python updateCentroids.py --step-num=0 --reducer --centroids initCentroids.csv --k 10 /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/input_part-00001\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-reducer_part-00000 -> /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/output/part-00000\n",
      "Moving /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/step-0-reducer_part-00001 -> /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/output/part-00001\n",
      "Streaming final output from /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072/output\n",
      "removing tmp directory /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/updateCentroids.Jacob.20150527.174046.437072\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/Users/Jacob/Desktop/255'\n",
    "output_dir = '/Users/Jacob/Desktop/255'\n",
    "CENTROID_FILE = input_dir + \"/initCentroids.csv\"\n",
    "!python updateCentroids.py --k=10 --runner=local $input_dir/processed_ALL.csv > $output_dir/interation1.csv --centroids=$CENTROID_FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the job done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmeans.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmeans.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.protocol import RawValueProtocol \n",
    "from mrjob.protocol import JSONValueProtocol \n",
    "from sys import stderr\n",
    "import random\n",
    "import sys\n",
    "from updateCentroids import MRUpdateCentroids\n",
    "from initCentroids import MRInitCentroids\n",
    "import numpy as np\n",
    "import pickle\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "# Create unique output directory in the student's s3_bucket\n",
    "def outPutToFile(job, runner, fileName, catchKey=0):\n",
    "    f = open(fileName, \"w\")\n",
    "    ADC = []\n",
    "    for line in runner.stream_output():\n",
    "        key, value = job.parse_output_line(line)\n",
    "        if catchKey == 1:\n",
    "            ADC.append(key)\n",
    "        #print key, value\n",
    "        f.write(value.strip()+'\\n')\n",
    "    f.close()\n",
    "    return None if len(ADC) == 0 else np.mean(ADC)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = sys.argv[1:]\n",
    "    output_dir = \"/Users/Jacob/Desktop/255/\" + str(uuid.uuid4())\n",
    "    INIT_CENTROIDS = output_dir + \"/centroids000\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    ADC = []\n",
    "    #ADC_FILE = \"/Users/Jacob/Desktop/255/ADC10-1.p\"\n",
    "    \n",
    "    choose_centroids_job = MRInitCentroids(args=args)\n",
    "    with choose_centroids_job.make_runner() as choose_centroids_runner:\n",
    "        choose_centroids_runner.run()\n",
    "        outPutToFile(choose_centroids_job, choose_centroids_runner, INIT_CENTROIDS)\n",
    "        i = 1\n",
    "        CENTROIDS_FILE = INIT_CENTROIDS\n",
    "        while True:\n",
    "            #print \"Iteration #%i\" % i\n",
    "            update_centroids_job = MRUpdateCentroids(args=args + ['--centroids='+CENTROIDS_FILE])\n",
    "            with update_centroids_job.make_runner() as update_centroids_runner:\n",
    "                update_centroids_runner.run()\n",
    "                CENTROIDS_FILE = INIT_CENTROIDS + str(i)\n",
    "                ADC.append(outPutToFile(update_centroids_job, update_centroids_runner,CENTROIDS_FILE, 1))\n",
    "            i += 1\n",
    "            if i == 10: break\n",
    "    #pickle.dump( ADC, open( ADC_FILE, \"wb\" ) )\n",
    "    print \",\".join([str(d) for d in ADC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.local\"\n",
      "1232.98027017,1150.05707298,1124.62757381,1119.08743696,1116.7307784,1116.52608811,1116.97294134,1117.43279811,1117.64310951\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/Users/Jacob/Desktop/255'\n",
    "!python kmeans.py --k=10 --l=800 --runner=local $input_dir/processed_ALL.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 j-2CP51XHZ0BZCQ ec2-54-158-231-241.compute-1.amazonaws.com WAITING\n",
      "1 j-2YTN78MP8WQG9 ec2-54-161-53-198.compute-1.amazonaws.com WAITING\n",
      "2 j-2HYK32Q58967A ec2-54-81-64-157.compute-1.amazonaws.com WAITING\n",
      "3 j-11HA0APWXXDQN ec2-54-81-217-77.compute-1.amazonaws.com WAITING\n",
      "4 j-34852Y03UYJ9J ec2-54-224-0-158.compute-1.amazonaws.com WAITING\n",
      "5 j-3R0H4CX9PUGQZ ec2-54-162-188-199.compute-1.amazonaws.com WAITING\n",
      "6 j-1FVV0CQW6H8NB ec2-54-144-57-57.compute-1.amazonaws.com WAITING\n",
      "7 j-23GGEIWFSWTLY ec2-54-162-37-207.compute-1.amazonaws.com WAITING\n",
      "8 j-2V7DNF88G388D ec2-54-81-125-178.compute-1.amazonaws.com RUNNING\n",
      "9 j-1E99KVYNES7B4 ec2-54-81-61-24.compute-1.amazonaws.com RUNNING\n",
      "j-2CP51XHZ0BZCQ ec2-54-158-231-241.compute-1.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "from find_waiting_flow import *\n",
    "flows_dict = find_waiting_flow(key_id,secret_key)\n",
    "flow_id, node = (flows_dict[0]['flow_id'],flows_dict[0]['node'])\n",
    "print flow_id, node\n",
    "input_file = 'hdfs://'+node+':9000/weather.raw_data/ALL.csv_4'\n",
    "#input_file = 's3://weather.raw_data/ALL.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://cse-z2tao/eae43fb9-b04f-4372-ba24-6891bb98bd06--processed/\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# Create unique output directory in the student's s3_bucket\n",
    "output_dir = s3_bucket + str(uuid.uuid4()) + \"--processed/\"\n",
    "\n",
    "print output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/Jacob/.mrjob.conf\n",
      "creating tmp directory /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.013003.464511\n",
      "Copying non-input files into s3://cse-z2tao/tmp/preprocess1.Jacob.20150530.013003.464511/files/\n",
      "Adding our job to existing job flow j-2CP51XHZ0BZCQ\n",
      "Job launched 31.9s ago, status RUNNING: Running step (preprocess1.Jacob.20150530.013003.464511: Step 1 of 1)\n",
      "Opening ssh tunnel to Hadoop job tracker\n",
      "Connect to job tracker at: http://localhost:40666/jobtracker.jsp\n",
      "Job launched 65.1s ago, status RUNNING: Running step (preprocess1.Jacob.20150530.013003.464511: Step 1 of 1)\n",
      "Unable to load progress from job tracker\n",
      "Job launched 97.3s ago, status RUNNING: Running step (preprocess1.Jacob.20150530.013003.464511: Step 1 of 1)\n",
      "Job completed.\n",
      "Running time was 104.0s (not counting time spent waiting for the EC2 instances)\n",
      "Fetching counters from SSH...\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Streaming final output from s3://cse-z2tao/eae43fb9-b04f-4372-ba24-6891bb98bd06--processed/\n",
      "removing tmp directory /var/folders/3y/n2gj1lc949l2bg1n6gpt8_m40000gn/T/preprocess1.Jacob.20150530.013003.464511\n",
      "Removing all files in s3://cse-z2tao/tmp/preprocess1.Jacob.20150530.013003.464511/\n",
      "Killing our SSH tunnel (pid 6974)\n"
     ]
    }
   ],
   "source": [
    "!python preprocess1.py --runner=emr $input_file --emr-job-flow-id=$flow_id --output-dir=$output_dir > processedC1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### There're in total 2097573 Non-TMAX entries, 44149 TMAX entries that have more than 50 missing values, and 197875 entries that are valid by definition. Such result is obtained from running ALL.csv_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iteration for k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 j-2CP51XHZ0BZCQ ec2-54-158-231-241.compute-1.amazonaws.com WAITING\n",
      "1 j-2HYK32Q58967A ec2-54-81-64-157.compute-1.amazonaws.com WAITING\n",
      "2 j-11HA0APWXXDQN ec2-54-81-217-77.compute-1.amazonaws.com WAITING\n",
      "3 j-34852Y03UYJ9J ec2-54-224-0-158.compute-1.amazonaws.com WAITING\n",
      "4 j-3R0H4CX9PUGQZ ec2-54-162-188-199.compute-1.amazonaws.com WAITING\n",
      "5 j-1FVV0CQW6H8NB ec2-54-144-57-57.compute-1.amazonaws.com WAITING\n",
      "6 j-1967XWTO7DWZ2 ec2-54-92-144-129.compute-1.amazonaws.com RUNNING\n",
      "7 j-2V7DNF88G388D ec2-54-81-125-178.compute-1.amazonaws.com RUNNING\n",
      "8 j-1E99KVYNES7B4 ec2-54-81-61-24.compute-1.amazonaws.com RUNNING\n",
      "9 j-2YTN78MP8WQG9 ec2-54-161-53-198.compute-1.amazonaws.com RUNNING\n",
      "j-2HYK32Q58967A ec2-54-81-64-157.compute-1.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "from find_waiting_flow import *\n",
    "flows_dict = find_waiting_flow(key_id,secret_key)\n",
    "flow_id, node = (flows_dict[1]['flow_id'],flows_dict[1]['node'])\n",
    "print flow_id, node\n",
    "local_out_dir = \"iters10\"\n",
    "#input_file = 'hdfs://'+node+':9000/weather.raw_data/ALL.csv_64'\n",
    "#input_file = 's3://weather.raw_data/ALL.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.emr\"\r\n"
     ]
    }
   ],
   "source": [
    "!python kmeans.py --k=10 --l=190000 --runner=emr $s3_bucket/processedCC --emr-job-flow-id=$flow_id > $local_out_dir/iter10num5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iteration for k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 j-2CP51XHZ0BZCQ ec2-54-158-231-241.compute-1.amazonaws.com WAITING\n",
      "1 j-2YTN78MP8WQG9 ec2-54-161-53-198.compute-1.amazonaws.com WAITING\n",
      "2 j-2HYK32Q58967A ec2-54-81-64-157.compute-1.amazonaws.com WAITING\n",
      "3 j-11HA0APWXXDQN ec2-54-81-217-77.compute-1.amazonaws.com WAITING\n",
      "4 j-34852Y03UYJ9J ec2-54-224-0-158.compute-1.amazonaws.com WAITING\n",
      "5 j-1FVV0CQW6H8NB ec2-54-144-57-57.compute-1.amazonaws.com WAITING\n",
      "6 j-1967XWTO7DWZ2 ec2-54-92-144-129.compute-1.amazonaws.com RUNNING\n",
      "7 j-2V7DNF88G388D ec2-54-81-125-178.compute-1.amazonaws.com RUNNING\n",
      "8 j-1E99KVYNES7B4 ec2-54-81-61-24.compute-1.amazonaws.com RUNNING\n",
      "9 j-3R0H4CX9PUGQZ ec2-54-162-188-199.compute-1.amazonaws.com RUNNING\n",
      "j-2YTN78MP8WQG9 ec2-54-161-53-198.compute-1.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "from find_waiting_flow import *\n",
    "flows_dict = find_waiting_flow(key_id,secret_key)\n",
    "flow_id, node = (flows_dict[1]['flow_id'],flows_dict[1]['node'])\n",
    "print flow_id, node\n",
    "local_out_dir = \"iters30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.emr\"\r\n"
     ]
    }
   ],
   "source": [
    "!python kmeans.py --k=30 --l=190000 --runner=emr $s3_bucket/processedCC --emr-job-flow-id=$flow_id > $local_out_dir/iter30num0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iteration for k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 j-1E99KVYNES7B4 ec2-54-81-61-24.compute-1.amazonaws.com WAITING\n",
      "1 j-2CP51XHZ0BZCQ ec2-54-158-231-241.compute-1.amazonaws.com WAITING\n",
      "2 j-2YTN78MP8WQG9 ec2-54-161-53-198.compute-1.amazonaws.com WAITING\n",
      "3 j-2HYK32Q58967A ec2-54-81-64-157.compute-1.amazonaws.com WAITING\n",
      "4 j-11HA0APWXXDQN ec2-54-81-217-77.compute-1.amazonaws.com WAITING\n",
      "5 j-34852Y03UYJ9J ec2-54-224-0-158.compute-1.amazonaws.com WAITING\n",
      "6 j-3R0H4CX9PUGQZ ec2-54-162-188-199.compute-1.amazonaws.com WAITING\n",
      "7 j-1FVV0CQW6H8NB ec2-54-144-57-57.compute-1.amazonaws.com WAITING\n",
      "8 j-23GGEIWFSWTLY ec2-54-162-37-207.compute-1.amazonaws.com WAITING\n",
      "9 j-2V7DNF88G388D ec2-54-81-125-178.compute-1.amazonaws.com RUNNING\n",
      "j-2CP51XHZ0BZCQ ec2-54-158-231-241.compute-1.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "from find_waiting_flow import *\n",
    "flows_dict = find_waiting_flow(key_id,secret_key)\n",
    "flow_id, node = (flows_dict[1]['flow_id'],flows_dict[1]['node'])\n",
    "print flow_id, node\n",
    "local_out_dir = \"iters100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.emr\"\r\n"
     ]
    }
   ],
   "source": [
    "!python kmeans.py --k=100 --l=190000 --runner=emr $s3_bucket/processedCC --emr-job-flow-id=$flow_id > $local_out_dir/iter100num8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for different k with 10 variantions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = \"iters10\"\n",
    "ys = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.startswith(\"iter\"):\n",
    "        ys.append([float(d) for d in open(data_dir+\"/\"+filename).read().strip().split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning:\n",
      "\n",
      "A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~coolmich00/163.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "scatters = []\n",
    "for i in range(len(ys)):\n",
    "    scatters.append(Scatter(\n",
    "        x=range(9),\n",
    "        y=ys[i]\n",
    "    ))\n",
    "py.iplot(scatters, filename='kmeans10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"iters30\"\n",
    "ys = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.startswith(\"iter\"):\n",
    "        ys.append([float(d) for d in open(data_dir+\"/\"+filename).read().strip().split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning:\n",
      "\n",
      "A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~coolmich00/169.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatters = []\n",
    "for i in range(len(ys)):\n",
    "    scatters.append(Scatter(\n",
    "        x=range(9),\n",
    "        y=ys[i]\n",
    "    ))\n",
    "py.iplot(scatters, filename='kmeans30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"iters100\"\n",
    "ys = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.startswith(\"iter\"):\n",
    "        ys.append([float(d) for d in open(data_dir+\"/\"+filename).read().strip().split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning:\n",
      "\n",
      "A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~coolmich00/170.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatters = []\n",
    "for i in range(len(ys)):\n",
    "    scatters.append(Scatter(\n",
    "        x=range(9),\n",
    "        y=ys[i]\n",
    "    ))\n",
    "py.iplot(scatters, filename='kmeans100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### There're in total 2097573 Non-TMAX entries, 44149 TMAX entries that have more than 50 missing values, and 197875 entries that are valid by definition. Such result is obtained from running ALL.csv_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
