{
 "metadata": {
  "name": "",
  "signature": "sha256:f6029df50f9cc8c520689e7f2fbb758e6496844bbaaea3106dc3dd95989283b5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook demonstrates the use of S3 through boto.\n",
      "\n",
      "It is based on this [introduction](http://boto.readthedocs.org/en/latest/s3_tut.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from boto.s3.connection import S3Connection\n",
      "from boto.s3.key import Key\n",
      "import os,pickle\n",
      "dir=os.environ['EC2_VAULT']\n",
      "Creds=pickle.load(open(dir+'/Creds.pkl','rb'))\n",
      "aws_access_key_id=Creds['launcher']['key_id']\n",
      "aws_secret_access_key=Creds['launcher']['secret_key']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn=S3Connection(aws_access_key_id, aws_secret_access_key)\n",
      "conn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "S3Connection:s3.amazonaws.com"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bucket=conn.create_bucket('ioperformance.bucket')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from boto.s3.connection import Location\n",
      "#bucket_in_europe=conn.create_bucket('ioperformance.europe.bucket',location=Location.EU)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rs = conn.get_all_buckets()\n",
      "rs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[<Bucket: NCDC.weather>,\n",
        " <Bucket: Yoav.Freund.packages>,\n",
        " <Bucket: chuan.bucket>,\n",
        " <Bucket: costaszarifisbucket>,\n",
        " <Bucket: dlisuk291>,\n",
        " <Bucket: dlisuk_291>,\n",
        " <Bucket: elgehelge>,\n",
        " <Bucket: guy_fawkes.bucket>,\n",
        " <Bucket: huaipengzhang>,\n",
        " <Bucket: ioperformance.bucket>,\n",
        " <Bucket: j2wen>,\n",
        " <Bucket: jiz173>,\n",
        " <Bucket: kritika.hadoop>,\n",
        " <Bucket: lge-bucket>,\n",
        " <Bucket: lgetest2>,\n",
        " <Bucket: lojin>,\n",
        " <Bucket: mkirby>,\n",
        " <Bucket: mrjob-1c3fbcb98956a5df>,\n",
        " <Bucket: mrjob-21609fa0385bafb0>,\n",
        " <Bucket: mrjob-2a08d59436b6210f>,\n",
        " <Bucket: mrjob-2aa7bd80e225ee4a>,\n",
        " <Bucket: mrjob-31c653a515ba0f2e>,\n",
        " <Bucket: mrjob-32f7e93d8b2c9468>,\n",
        " <Bucket: mrjob-442485be511e89a6>,\n",
        " <Bucket: mrjob-4878a7dcf06ef83b>,\n",
        " <Bucket: mrjob-61da15fbd8023a3b>,\n",
        " <Bucket: mrjob-8e069cabc5ed5fce>,\n",
        " <Bucket: mrjob-91fa5c22614e17e0>,\n",
        " <Bucket: mrjob-af61e1dfef84f466>,\n",
        " <Bucket: mrjob-b1420e5a8a11a976>,\n",
        " <Bucket: mrjob-c166338e9f0d1725>,\n",
        " <Bucket: mrjob-c5d0d04e01bd0c3f>,\n",
        " <Bucket: mrjob-c6f98258978ef071>,\n",
        " <Bucket: mrjob-c826e7abb721352e>,\n",
        " <Bucket: mrjob-d22c82fc17b80dda>,\n",
        " <Bucket: mrjob-dd7bce2523dd73f8>,\n",
        " <Bucket: mrjob-de7301e1028541f1>,\n",
        " <Bucket: mrjob-e0f161b9031903a1>,\n",
        " <Bucket: murphynnn>,\n",
        " <Bucket: myjobflow2>,\n",
        " <Bucket: ning.bucket>,\n",
        " <Bucket: pvekris.bucket>,\n",
        " <Bucket: ruininghe>,\n",
        " <Bucket: s9xie>,\n",
        " <Bucket: sic046>,\n",
        " <Bucket: suvir>,\n",
        " <Bucket: vineel-bucket>,\n",
        " <Bucket: weather.ghnc>,\n",
        " <Bucket: weather.ncdc>,\n",
        " <Bucket: weather.raw_data>,\n",
        " <Bucket: weiwei.bucket>,\n",
        " <Bucket: woerns.bucket>,\n",
        " <Bucket: xintaochen>,\n",
        " <Bucket: xinxin.bucket>,\n",
        " <Bucket: ye.bucket>,\n",
        " <Bucket: yoav.hadoop>,\n",
        " <Bucket: yoav_student>,\n",
        " <Bucket: yuf>,\n",
        " <Bucket: yufei>,\n",
        " <Bucket: zhs015>,\n",
        " <Bucket: zsubucket>]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## THis is to be the script that populates the hdfs storage with all of the files in a given \n",
      "## S3 bucket.\n",
      "from time import time\n",
      "import os\n",
      "s3bucket='weather.raw_data'\n",
      "hadoop_dir='/'+s3bucket+'/'\n",
      "local_dir= '/tmp'\n",
      "bucket=conn.get_bucket('weather.raw_data')\n",
      "os.chdir('/t)\n",
      "for key in bucket.get_all_keys():\n",
      "    if key.name.endswith('.gz'):\n",
      "        \n",
      "        print 'GZ file: ',key.name\n",
      "        t1=time()\n",
      "        key.get_contents_to_filename(key.name)\n",
      "        t2=time()\n",
      "        os.cmd('gunzip '+key.name)\n",
      "        print key.name, 'took', time()-t1, 'to download'\n",
      "        sys.stdout.flush()\n",
      "    else:\n",
      "        print key.name\n",
      "        os.system('')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd /home/ubuntu/logs/\n",
      "!mkdir S3.experiments\n",
      "%cd S3.experiments\n",
      "!ls -lrt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/logs\n",
        "mkdir: cannot create directory `S3.experiments': File exists\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/logs/S3.experiments\n",
        "total 10850608\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu     1000000 Apr 25 16:14 BlockData1\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu   100000000 Apr 25 16:14 BlockData100\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu    10000000 Apr 25 16:14 BlockData10\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  1000000000 Apr 25 16:14 BlockData1000\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu 10000000000 Apr 25 23:38 BlockData10000\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "from time import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key in bucket.get_all_keys():\n",
      "    t1=time()\n",
      "    key.get_contents_to_filename(key.name)\n",
      "    print key.name, time()-t1\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BlockData1 0.0978999137878\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BlockData10 0.318012952805\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BlockData100 4.91138696671\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BlockData1000 60.3785459995\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k=Key(bucket)\n",
      "for filename in sorted(glob('BlockData*')):\n",
      "    t1=time()\n",
      "    k.key = filename\n",
      "    k.set_contents_from_filename(filename)\n",
      "    print filename, time()-t1\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BlockData1 0.223724842072\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BlockData10 0.482264041901\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BlockData100 5.80126094818\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BlockData1000 36.7268030643\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We get that the speed of retrieving from S3 is around 1-2GB/minute which is around 15-30MB/sec.\n",
      "Reading from local disk to memory can be done at the rate of around 1GB/sec. Reading or writing a 10GB is a hard to complete task.\n",
      "\n",
      "These measurements were done on April 26/2014, on an m3.xlarge ec2 instance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1000000000/60.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "16666666.666666666"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Comparing with the time to read 1GB into memory\n",
      "t1=time()\n",
      "file=open('BlockData10000','r')\n",
      "data=file.read()\n",
      "file.close()\n",
      "print time()-t1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "149.144545078\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is interesting that reading 10GB into memory takes much longer than 10 times reading 1GB into memory. (149 seconds as compared to one second).\n",
      "\n",
      "My guess is that the virtual machine, while in principle having access to 16GB, actually has to very gradually claim enough physical memory to perform the read.\n",
      "\n",
      "below is a snapshot of the **Top** command showing that the state of python just before completing the task."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      " 8624 ubuntu    20   0 10.9g  10g 9956 D    7 69.9   0:27.29 python                                 \n",
      "   37 root      20   0     0    0    0 S    2  0.0   0:05.56 kswapd0                                \n",
      " 8533 ubuntu    20   0  410m  73m 8008 S    0  0.5   0:03.27 ipython                                \n",
      "    1 root      20   0 24396 2144 1160 S    0  0.0   0:00.38 init                                   \n",
      "    2 root      20   0     0    0    0 S    0  0.0   0:00.00 kthreadd                               \n",
      "    3 root      20   0     0    0    0 S    0  0.0   0:01.40 ksoftirqd/0                            \n",
      "    4 root      20   0     0    0    0 S    0  0.0   0:00.00 kworker/0:0                            \n",
      "    5 root      20   0     0    0    0 S    0  0.0   0:00.01 kworker/u:0                            \n",
      "    6 root      RT   0     0    0    0 S    0  0.0   0:00.00 migration/0                            \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To upload a file to S3, here from ION, we use the \n",
      "\n",
      "`/oasis/projects/nsf/csd181/hadoop/s3-bash/s3-put -k AKIAI7AWJT7RBAPJX6WQ -s ~/.boto/secret -T /oasis/projects/nsf/csd181/yfreund/weather/processed/ALL.csv.gz /Weather.GHNC/ALL.csv.gz`\n",
      "\n",
      "This uses code that can be downloaded from https://github.com/cosmin/s3-bash\n",
      "\n",
      "Note that each file uploaded to S3 is limited to 5GB"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.mkdir()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "bucket=conn.get_bucket('weather.raw_data')\n",
      "json.dumps([key.name for key in bucket.get_all_keys()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "'[\"ALL.csv.gz\", \"ALL.csv_1024\", \"ALL.csv_128\", \"ALL.csv_16\", \"ALL.csv_2\", \"ALL.csv_2048\", \"ALL.csv_256\", \"ALL.csv_32\", \"ALL.csv_4\", \"ALL.csv_4096\", \"ALL.csv_512\", \"ALL.csv_64\", \"ALL.csv_8\", \"ALL.csv_8192\", \"gsod.all.tsv.gz\", \"gsod.all.tsv_1024\", \"gsod.all.tsv_128\", \"gsod.all.tsv_16\", \"gsod.all.tsv_16384\", \"gsod.all.tsv_2048\", \"gsod.all.tsv_256\", \"gsod.all.tsv_32\", \"gsod.all.tsv_32768\", \"gsod.all.tsv_4096\", \"gsod.all.tsv_512\", \"gsod.all.tsv_64\", \"gsod.all.tsv_65536\", \"gsod.all.tsv_8\", \"gsod.all.tsv_8192\"]'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}